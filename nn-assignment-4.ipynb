{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:05.893650Z",
     "iopub.status.busy": "2022-03-31T00:57:05.893124Z",
     "iopub.status.idle": "2022-03-31T00:57:07.108238Z",
     "shell.execute_reply": "2022-03-31T00:57:07.106926Z",
     "shell.execute_reply.started": "2022-03-31T00:57:05.893613Z"
    },
    "id": "0ecc69a6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample,shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:07.110112Z",
     "iopub.status.busy": "2022-03-31T00:57:07.109756Z",
     "iopub.status.idle": "2022-03-31T00:57:16.472812Z",
     "shell.execute_reply": "2022-03-31T00:57:16.471838Z",
     "shell.execute_reply.started": "2022-03-31T00:57:07.110081Z"
    },
    "id": "57caa904"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "from transformers import BertTokenizer, TFBertForQuestionAnswering\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:16.474653Z",
     "iopub.status.busy": "2022-03-31T00:57:16.474315Z",
     "iopub.status.idle": "2022-03-31T00:57:16.492721Z",
     "shell.execute_reply": "2022-03-31T00:57:16.491671Z",
     "shell.execute_reply.started": "2022-03-31T00:57:16.474612Z"
    },
    "id": "McuhMcv2r8E2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 21:32:00.083582: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:16.499941Z",
     "iopub.status.busy": "2022-03-31T00:57:16.499645Z",
     "iopub.status.idle": "2022-03-31T00:57:16.518903Z",
     "shell.execute_reply": "2022-03-31T00:57:16.518293Z",
     "shell.execute_reply.started": "2022-03-31T00:57:16.499908Z"
    },
    "id": "Y7N6wjoxsL_Y",
    "outputId": "1c632225-7870-41cc-b6a5-0106b43acfbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:16.520581Z",
     "iopub.status.busy": "2022-03-31T00:57:16.520164Z",
     "iopub.status.idle": "2022-03-31T00:57:45.592761Z",
     "shell.execute_reply": "2022-03-31T00:57:45.591774Z",
     "shell.execute_reply.started": "2022-03-31T00:57:16.520548Z"
    },
    "id": "1f140c33",
    "outputId": "86eab29b-f678-4eca-de4b-f1a629d3194e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some layers of TFBertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Use InceptionV3 model for image feature extraction\n",
    "# Instantiate CV model feature extractor and freeze layers\n",
    "base_model = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(None, None, 3),\n",
    "    pooling='max',\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "# Use BERT question answering model from Hugging Face\n",
    "# Download text feature extractor\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", )\n",
    "bertmodel = TFBertForQuestionAnswering.from_pretrained(\"bert-base-cased\")\n",
    "feature_extraction = pipeline('feature-extraction', model=bertmodel, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:45.595105Z",
     "iopub.status.busy": "2022-03-31T00:57:45.594737Z",
     "iopub.status.idle": "2022-03-31T00:57:46.012717Z",
     "shell.execute_reply": "2022-03-31T00:57:46.011715Z",
     "shell.execute_reply.started": "2022-03-31T00:57:45.595055Z"
    },
    "id": "8d422f72"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.preprocessing.image as image\n",
    "from skimage import io\n",
    "\n",
    "## PART 2: \n",
    "# - Extract features from image\n",
    "# - Extract features from question\n",
    "# - Combine image + question features\n",
    "imgsize = (600, 600)\n",
    "\n",
    "def padding(array, target_len=30):\n",
    "    array = np.array(array)\n",
    "    h = array.shape[0]\n",
    "    if h < target_len:\n",
    "        a = target_len - h\n",
    "        new = np.pad(array, pad_width=(0, a), mode='constant')\n",
    "    else:\n",
    "        new = array[0:target_len]\n",
    "\n",
    "    return new\n",
    "\n",
    "def extract_image(image_url):\n",
    "    imag = io.imread(image_url)\n",
    "    x = image.img_to_array(imag)\n",
    "    n = preprocess_input(x)\n",
    "    \n",
    "    # resize so all photos have same dim\n",
    "    size = imgsize\n",
    "    n = tf.keras.preprocessing.image.smart_resize(n, size)\n",
    "    return n\n",
    "\n",
    "def extract_image_features(n):\n",
    "    feature_vector = base_model.predict(n) \n",
    "    return feature_vector\n",
    "\n",
    "# Gets the most common answer for a given sample\n",
    "from scipy import stats as s\n",
    "def compute_answers(ans):\n",
    "    y = []\n",
    "    for i in ans:\n",
    "        y.append(i['answer'])\n",
    "        \n",
    "    answer = s.mode(y)[0]\n",
    "    return answer\n",
    "  \n",
    "\n",
    "# Gets most common 3000 answers out of given dataset\n",
    "from collections import Counter\n",
    "def init_answer_info(data):\n",
    "    answers = []\n",
    "    for i in data:\n",
    "        for j in i['answers']:\n",
    "            answers.append(j['answer'])\n",
    "        \n",
    "    occurence_count = Counter(answers)\n",
    "    most_common = occurence_count.most_common(3000)\n",
    "    most_common_words = []\n",
    "    for i in most_common:\n",
    "        most_common_words.append(i[0])\n",
    "\n",
    "    num_answers = len(most_common_words)\n",
    "    return num_answers, most_common_words\n",
    "\n",
    "def extract_pooled_text_embeddings(data, start, stop, dictval='question', T = 30):\n",
    "    token_ids = np.array([np.zeros(T)])\n",
    "    attn_mask = np.array([np.zeros(T)])\n",
    "    seg_ids = np.array([np.zeros(T)])\n",
    "    for vq in data[start:stop]:\n",
    "        question = vq[dictval]\n",
    "        tokens = tokenizer.tokenize(question)\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "\n",
    "        padded_tokens=tokens + ['[PAD]' for _ in range(T-len(tokens))]\n",
    "        this_attn_mask=[1 if token != '[PAD]' else 0 for token in padded_tokens  ]\n",
    "        seg_id=[0 for _ in range(len(padded_tokens))]\n",
    "        sent_ids=tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "\n",
    "        try:\n",
    "            token_ids = np.vstack([token_ids, sent_ids])\n",
    "            attn_mask = np.vstack([attn_mask, this_attn_mask])\n",
    "            seg_ids = np.vstack([seg_ids, seg_id])\n",
    "        except: \n",
    "            print('except')\n",
    "            sent_ids = sent_ids[0:30]\n",
    "            this_attn_mask = this_attn_mask[0:30]\n",
    "            seg_id = seg_id[0:30]\n",
    "            token_ids = np.vstack([token_ids, sent_ids])\n",
    "            attn_mask = np.vstack([attn_mask, this_attn_mask])\n",
    "            seg_ids = np.vstack([seg_ids, seg_id])\n",
    "\n",
    "    # Finished compiling batch, now feed batch to model\n",
    "    token_ids = np.delete(token_ids, 0, 0)\n",
    "    attn_mask = np.delete(attn_mask, 0, 0)\n",
    "    seg_ids = np.delete(seg_ids, 0, 0)\n",
    "\n",
    "    token_ids = token_ids.astype(np.int64)\n",
    "    tattn_mask = attn_mask.astype(np.int64)\n",
    "    seg_ids = seg_ids.astype(np.int64)\n",
    "\n",
    "    hidden, pooled = bertmodel(token_ids, attention_mask = attn_mask,token_type_ids = seg_ids, return_dict=False)\n",
    "    pooled_embeddings = np.array(pooled)\n",
    "        \n",
    "    return pooled_embeddings\n",
    "\n",
    "\n",
    "def extract_pooled_answer_embeddings(data, start, stop, dictval='answer', T = 6):\n",
    "    token_ids = np.array([np.zeros(T)])\n",
    "    attn_mask = np.array([np.zeros(T)])\n",
    "    seg_ids = np.array([np.zeros(T)])\n",
    "    for vq in data:\n",
    "        question = vq[0]\n",
    "        tokens = tokenizer.tokenize(question)\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "#         print(f\"Final Length: {len(tokens)}\")\n",
    "\n",
    "        padded_tokens=tokens + ['[PAD]' for _ in range(T-len(tokens))]\n",
    "        this_attn_mask=[1 if token != '[PAD]' else 0 for token in padded_tokens  ]\n",
    "        seg_id=[0 for _ in range(len(padded_tokens))]\n",
    "        sent_ids=tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "\n",
    "        try:\n",
    "            token_ids = np.vstack([token_ids, sent_ids])\n",
    "            attn_mask = np.vstack([attn_mask, this_attn_mask])\n",
    "            seg_ids = np.vstack([seg_ids, seg_id])\n",
    "        except: \n",
    "            print('answer except')\n",
    "            sent_ids = sent_ids[0:T]\n",
    "            this_attn_mask = this_attn_mask[0:T]\n",
    "            seg_id = seg_id[0:T]\n",
    "            token_ids = np.vstack([token_ids, sent_ids])\n",
    "            attn_mask = np.vstack([attn_mask, this_attn_mask])\n",
    "            seg_ids = np.vstack([seg_ids, seg_id])\n",
    "\n",
    "    # Finished compiling batch, now feed batch to model\n",
    "    token_ids = np.delete(token_ids, 0, 0)\n",
    "    attn_mask = np.delete(attn_mask, 0, 0)\n",
    "    seg_ids = np.delete(seg_ids, 0, 0)\n",
    "\n",
    "    token_ids = token_ids.astype(np.int64)\n",
    "    tattn_mask = attn_mask.astype(np.int64)\n",
    "    seg_ids = seg_ids.astype(np.int64)\n",
    "\n",
    "    hidden, pooled = bertmodel(token_ids, attention_mask = attn_mask,token_type_ids = seg_ids, return_dict=False)\n",
    "    pooled_embeddings = np.array(pooled)\n",
    "        \n",
    "    return pooled_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:46.016820Z",
     "iopub.status.busy": "2022-03-31T00:57:46.016477Z",
     "iopub.status.idle": "2022-03-31T00:57:46.029742Z",
     "shell.execute_reply": "2022-03-31T00:57:46.029039Z",
     "shell.execute_reply.started": "2022-03-31T00:57:46.016759Z"
    },
    "id": "c67dadba"
   },
   "outputs": [],
   "source": [
    "# You can build and train any model using the input images, input questions, and labels\n",
    "max_length = 30\n",
    "def get_feature_vectors(data, start = 0, stop = 50):\n",
    "    img_train = np.zeros((1, imgsize[0], imgsize[1], 3))\n",
    "    for i, vq in enumerate(data[start:stop]):\n",
    "          # Extract features describing the image\n",
    "          image_name = vq['image']\n",
    "          image_url = img_dir + image_name\n",
    "          image_vec = extract_image(image_url)\n",
    "          n1, n2, n3 = image_vec.shape\n",
    "          image_vec = np.reshape(image_vec, (1, n1, n2, n3))\n",
    "          img_train = np.vstack([img_train, image_vec])\n",
    "\n",
    "    img_train = np.delete(img_train, 0, 0)    \n",
    "    image_feature = extract_image_features(img_train)\n",
    "\n",
    "    # Extract features describing the question\n",
    "    question_feature = extract_pooled_text_embeddings(data, start, stop)\n",
    "        \n",
    "    # # Create a multimodal feature to represent both the image and question (e.g. concatenate, multiply, etc.)\n",
    "    multimodal_features = np.concatenate([question_feature, image_feature], axis=1)\n",
    "\n",
    "    # get answers\n",
    "    vq = data[start]\n",
    "    answers = vq['answers']\n",
    "    label = compute_answers(answers)\n",
    "    y=label\n",
    "    for vq in data[start+1:stop]:\n",
    "        answers = vq['answers']\n",
    "        label = compute_answers(answers)\n",
    "        y = np.vstack([y, label])\n",
    "        \n",
    "    return multimodal_features, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-03-31T00:57:46.031612Z",
     "iopub.status.busy": "2022-03-31T00:57:46.030806Z",
     "iopub.status.idle": "2022-03-31T00:57:47.287744Z",
     "shell.execute_reply": "2022-03-31T00:57:47.286903Z",
     "shell.execute_reply.started": "2022-03-31T00:57:46.031580Z"
    },
    "id": "650e9e07",
    "outputId": "e67c4d32-1615-4ec9-c0cb-8b5cd31fa08f"
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 54] Connection reset by peer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b6/qqcnr7cj16sd1r0nn3p4f_sw0000gn/T/ipykernel_15203/440528467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mannotation_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/%s.json\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msplit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_top_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_train_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_answer_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))"
     ]
    }
   ],
   "source": [
    "img_dir = \"https://vizwiz.cs.colorado.edu//VizWiz_visualization_img/\"\n",
    "split = 'train' \n",
    "annotation_file = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/%s.json\" %split\n",
    "\n",
    "split_data = requests.get(annotation_file, allow_redirects=True)\n",
    "data = split_data.json()\n",
    "num_top_answers, top_train_answers = init_answer_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T01:05:43.773640Z",
     "iopub.status.busy": "2022-03-31T01:05:43.773327Z",
     "iopub.status.idle": "2022-03-31T01:40:56.425687Z",
     "shell.execute_reply": "2022-03-31T01:40:56.424767Z",
     "shell.execute_reply.started": "2022-03-31T01:05:43.773604Z"
    },
    "id": "HC8f_rOLeH75",
    "outputId": "d04df461-b758-4bc9-9fcc-a47bd065d1b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# download the training samples - start with 3000 for now\n",
    "\n",
    "X_train = np.zeros([1, 2078])\n",
    "y_train = np.zeros(8)\n",
    "# y_train = np.load('trainy_data.npy')\n",
    "# X_train = np.load('trainX_data (1).npy')\n",
    "\n",
    "for start in range(0, 2000, 50):\n",
    "    print(start)\n",
    "    stop = start+100\n",
    "    X_train_iter, y_train_iter = get_feature_vectors(data, start=start, stop=stop)\n",
    "\n",
    "    # get answer label embeddings\n",
    "    y_embed = extract_pooled_answer_embeddings(y_train_iter, start, stop, dictval='answer', T = 8)\n",
    "    \n",
    "    X_train = np.vstack([X_train, X_train_iter])\n",
    "    y_train = np.vstack([y_train, y_embed])\n",
    "    \n",
    "    np.save('trainX_data_2000_v2', X_train)\n",
    "    np.save('trainy_data_2000_v2', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.delete(X_train, 0, 0)\n",
    "y_train = np.delete(y_train, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('trainX_data_2000_v2', X_train)\n",
    "np.save('trainy_data_2000_v2', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:17:23.457582Z",
     "iopub.status.busy": "2022-03-31T00:17:23.456539Z",
     "iopub.status.idle": "2022-03-31T00:17:23.466850Z",
     "shell.execute_reply": "2022-03-31T00:17:23.465722Z",
     "shell.execute_reply.started": "2022-03-31T00:17:23.457527Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_temp.shape# = X_train.copy()\n",
    "#y_train_temp = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T23:09:59.676615Z",
     "iopub.status.busy": "2022-03-30T23:09:59.676326Z",
     "iopub.status.idle": "2022-03-30T23:09:59.707220Z",
     "shell.execute_reply": "2022-03-30T23:09:59.705834Z",
     "shell.execute_reply.started": "2022-03-30T23:09:59.676584Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.delete(X_train, 0, 0)\n",
    "y_train = np.delete(y_train, 0, 0)\n",
    "\n",
    "# np.save('trainX_data', X_train)\n",
    "# np.save('trainy_data', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:17:48.034590Z",
     "iopub.status.busy": "2022-03-31T00:17:48.034237Z",
     "iopub.status.idle": "2022-03-31T00:17:48.066023Z",
     "shell.execute_reply": "2022-03-31T00:17:48.064985Z",
     "shell.execute_reply.started": "2022-03-31T00:17:48.034558Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.load('trainX_data_5000.npy')\n",
    "y_train = np.load('trainy_data_5000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-03-30T23:10:54.591187Z",
     "iopub.status.busy": "2022-03-30T23:10:54.590115Z",
     "iopub.status.idle": "2022-03-30T23:10:54.597674Z",
     "shell.execute_reply": "2022-03-30T23:10:54.596183Z",
     "shell.execute_reply.started": "2022-03-30T23:10:54.591130Z"
    },
    "id": "Ue2OVof__V17"
   },
   "outputs": [],
   "source": [
    "# d = top_train_answers\n",
    "# question_feature = feature_extraction(d)\n",
    "# question_feature = np.array(question_feature)\n",
    "\n",
    "# embedding_matrix = {}\n",
    "\n",
    "# max_answer_length = 0\n",
    "# for q in question_feature:\n",
    "#   if len(q) > max_answer_length:\n",
    "#     max_answer_length = len(q[0])\n",
    "\n",
    "\n",
    "# print(f'Max answer length: {max_answer_length}')\n",
    "# try:\n",
    "#     for i, (key, qfeats)  in enumerate(zip(d, question_feature)):\n",
    "#         word_embedding = padding(question_feature[i][0], target_len = max_answer_length)\n",
    "#         embedding_matrix[key] = word_embedding\n",
    " \n",
    "# except:\n",
    "#     print(f'Except: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T01:04:51.939483Z",
     "iopub.status.busy": "2022-03-31T01:04:51.939195Z",
     "iopub.status.idle": "2022-03-31T01:04:52.272795Z",
     "shell.execute_reply": "2022-03-31T01:04:52.272120Z",
     "shell.execute_reply.started": "2022-03-31T01:04:51.939451Z"
    },
    "id": "VgzC_4TUJ5Dc"
   },
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "import pandas as pd\n",
    "# pd.DataFrame(embedding_matrix).to_csv('answer_embedding_matrix2')\n",
    "\n",
    "d = pd.read_csv('../input/bert-answer-embeddings/answer_embedding_matrix')\n",
    "d.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "embedding_matrix = {}\n",
    "for col in d.columns:\n",
    "  embedding_matrix[col] = np.array(d[col])\n",
    "\n",
    "max_answer_length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'VizWiz_val_00000000.jpg',\n",
       " 'question': 'Ok. There is another picture I hope it is a better one.',\n",
       " 'answers': [{'answer': 'unanswerable', 'answer_confidence': 'yes'},\n",
       "  {'answer': 'unanswerable', 'answer_confidence': 'yes'},\n",
       "  {'answer': 'unanswerable', 'answer_confidence': 'yes'},\n",
       "  {'answer': 'unanswerable', 'answer_confidence': 'yes'},\n",
       "  {'answer': 'unanswerable', 'answer_confidence': 'maybe'},\n",
       "  {'answer': 'unanswerable', 'answer_confidence': 'yes'},\n",
       "  {'answer': 'unanswerable', 'answer_confidence': 'yes'},\n",
       "  {'answer': 'unanswerable', 'answer_confidence': 'no'},\n",
       "  {'answer': 'cannot repair this computer automatically',\n",
       "   'answer_confidence': 'maybe'},\n",
       "  {'answer': 'blank screen', 'answer_confidence': 'yes'}],\n",
       " 'answer_type': 'unanswerable',\n",
       " 'answerable': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T23:14:46.527240Z",
     "iopub.status.busy": "2022-03-30T23:14:46.526500Z",
     "iopub.status.idle": "2022-03-30T23:39:02.637800Z",
     "shell.execute_reply": "2022-03-30T23:39:02.636651Z",
     "shell.execute_reply.started": "2022-03-30T23:14:46.527200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b6/qqcnr7cj16sd1r0nn3p4f_sw0000gn/T/ipykernel_15203/1684367814.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  question_feature = np.array(question_feature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2078)\n",
      "50\n",
      "(50, 2078)\n",
      "100\n",
      "(50, 2078)\n",
      "150\n",
      "(50, 2078)\n",
      "200\n",
      "(50, 2078)\n",
      "250\n",
      "(50, 2078)\n",
      "300\n",
      "(50, 2078)\n",
      "350\n",
      "(50, 2078)\n",
      "400\n",
      "(50, 2078)\n",
      "450\n",
      "(50, 2078)\n",
      "500\n",
      "(50, 2078)\n",
      "550\n",
      "(50, 2078)\n",
      "600\n",
      "(50, 2078)\n",
      "650\n",
      "(50, 2078)\n",
      "700\n",
      "(50, 2078)\n",
      "750\n",
      "(50, 2078)\n",
      "800\n",
      "(50, 2078)\n",
      "850\n",
      "(50, 2078)\n",
      "900\n",
      "(50, 2078)\n",
      "950\n",
      "(50, 2078)\n"
     ]
    }
   ],
   "source": [
    "#Load validation set\n",
    "split = 'val'\n",
    "# split = 'test'\n",
    "annotation_file = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/%s.json\" %split\n",
    "split_data = requests.get(annotation_file, allow_redirects=True)\n",
    "val_data = split_data.json()\n",
    "\n",
    "\n",
    "X_val = np.zeros([1, 2078])\n",
    "y_val = np.zeros(1)\n",
    "for start in range(0, 1000, 50):\n",
    "    print(start)\n",
    "    stop = start+50\n",
    "    X_val_iter, y_val_iter = get_feature_vectors(val_data, start=start, stop=stop)\n",
    "\n",
    "    X_val = np.vstack([X_val, X_val_iter])\n",
    "    y_val = np.vstack([y_val, y_val_iter])\n",
    "    \n",
    "    np.save('valX_data', X_val)\n",
    "    np.save('valy_data', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.delete(X_val, 0, 0)\n",
    "y_val = np.delete(y_val, 0, 0)\n",
    "np.save('valX_data', X_val)\n",
    "np.save('valy_data', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T23:54:17.452054Z",
     "iopub.status.busy": "2022-03-30T23:54:17.451278Z",
     "iopub.status.idle": "2022-03-30T23:54:17.460203Z",
     "shell.execute_reply": "2022-03-30T23:54:17.459091Z",
     "shell.execute_reply.started": "2022-03-30T23:54:17.451976Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(y_train):\n",
    "    if y[0] in ['unanswerable', 'unsuitable', 'unsuitable image']:\n",
    "        print('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T23:56:00.722127Z",
     "iopub.status.busy": "2022-03-30T23:56:00.721523Z",
     "iopub.status.idle": "2022-03-30T23:56:00.764746Z",
     "shell.execute_reply": "2022-03-30T23:56:00.763819Z",
     "shell.execute_reply.started": "2022-03-30T23:56:00.722073Z"
    },
    "id": "bf606f99"
   },
   "outputs": [],
   "source": [
    "# Remove training samples where label is not in the answer bank\n",
    "# remove training samples that are 'unanswerable', 'unsuitable', 'unsuitable image'\n",
    "num_not_found = 0\n",
    "index_not_found = []\n",
    "y_train_index  = []\n",
    "for i, y in enumerate(y_train):\n",
    "    if y[0] in ['unanswerable', 'unsuitable', 'unsuitable image']:\n",
    "        index_not_found.append(i)\n",
    "        continue\n",
    "    try:\n",
    "        y_train_index.append(embedding_matrix[y[0]])\n",
    "    except:\n",
    "        num_not_found+=1\n",
    "        index_not_found.append(i)\n",
    "        \n",
    "print(num_not_found)\n",
    "\n",
    "# remove the data if label not in dict\n",
    "y_train = np.delete(y_train, [index_not_found])\n",
    "X_train = np.delete(X_train, [index_not_found], axis=0)\n",
    "\n",
    "y_train_index = np.array(y_train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T23:56:14.052529Z",
     "iopub.status.busy": "2022-03-30T23:56:14.052214Z",
     "iopub.status.idle": "2022-03-30T23:56:14.068921Z",
     "shell.execute_reply": "2022-03-30T23:56:14.067303Z",
     "shell.execute_reply.started": "2022-03-30T23:56:14.052497Z"
    },
    "id": "87396c11"
   },
   "outputs": [],
   "source": [
    "# Repeat for validation set\n",
    "num_not_found = 0\n",
    "index_not_found = []\n",
    "y_val_index = []\n",
    "for i, y in enumerate(y_val):\n",
    "    if y[0] in ['unanswerable', 'unsuitable', 'unsuitable image']:\n",
    "        index_not_found.append(i)\n",
    "        continue\n",
    "    try:\n",
    "        y_val_index.append(embedding_matrix[y[0]])\n",
    "    except:\n",
    "        num_not_found+=1\n",
    "        index_not_found.append(i)\n",
    "        \n",
    "print(num_not_found)\n",
    "\n",
    "# remove the data if label not in dict\n",
    "y_val = np.delete(y_val, [index_not_found])\n",
    "X_val = np.delete(X_val, [index_not_found], axis=0)\n",
    "\n",
    "y_val_index = np.array(y_val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:09:55.568166Z",
     "iopub.status.busy": "2022-03-31T00:09:55.567569Z",
     "iopub.status.idle": "2022-03-31T00:09:56.178790Z",
     "shell.execute_reply": "2022-03-31T00:09:56.177655Z",
     "shell.execute_reply.started": "2022-03-31T00:09:55.568125Z"
    },
    "id": "16fdf193"
   },
   "outputs": [],
   "source": [
    "# Now create the multimodal model\n",
    "import keras\n",
    "from keras import layers, Input, Model, optimizers\n",
    "\n",
    "inputs = Input(shape=(1, X_train.shape[1]))\n",
    "x = layers.Bidirectional(layers.LSTM(100))(inputs)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Flatten()(x)\n",
    "out = layers.Dense(max_answer_length, activation=\"softmax\")(x) \n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(\n",
    "  optimizer = 'adam',\n",
    "  loss=tf.keras.losses.MeanSquaredError(),\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T23:57:27.374363Z",
     "iopub.status.busy": "2022-03-30T23:57:27.373616Z",
     "iopub.status.idle": "2022-03-30T23:57:27.382030Z",
     "shell.execute_reply": "2022-03-30T23:57:27.380762Z",
     "shell.execute_reply.started": "2022-03-30T23:57:27.374311Z"
    },
    "id": "3auKtMZobPu2"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T23:57:33.502793Z",
     "iopub.status.busy": "2022-03-30T23:57:33.502412Z",
     "iopub.status.idle": "2022-03-30T23:57:33.510159Z",
     "shell.execute_reply": "2022-03-30T23:57:33.508309Z",
     "shell.execute_reply.started": "2022-03-30T23:57:33.502716Z"
    },
    "id": "2ebe2786"
   },
   "outputs": [],
   "source": [
    "# Reshape train and test inputs\n",
    "n1, n2 = X_train.shape\n",
    "X_train =  X_train.reshape(n1, 1, n2)\n",
    "y_train_index =  y_train_index.reshape(n1, max_answer_length)\n",
    "\n",
    "n1, n2 = X_val.shape\n",
    "X_val = X_val.reshape(n1, 1, n2)\n",
    "y_val_index = y_val_index.reshape(n1,  max_answer_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T17:23:59.291613Z",
     "iopub.status.busy": "2022-03-30T17:23:59.291422Z",
     "iopub.status.idle": "2022-03-30T17:23:59.301557Z",
     "shell.execute_reply": "2022-03-30T17:23:59.300784Z",
     "shell.execute_reply.started": "2022-03-30T17:23:59.291581Z"
    },
    "id": "orwkPwKN2TUU"
   },
   "outputs": [],
   "source": [
    "# run answers thru bert to get bert embedding\n",
    "# get embedding matrix\n",
    "# loss function = mse -> minimize euclidean distance\n",
    "# last layer outputs vector that is same size as bert embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2022-03-31T00:03:14.748504Z",
     "shell.execute_reply": "2022-03-31T00:03:14.746755Z",
     "shell.execute_reply.started": "2022-03-31T00:00:57.497450Z"
    },
    "id": "5332fcca"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Train the model\n",
    "info = model.fit(X_train, y_train_index, batch_size=1000, epochs=100, validation_data=(X_val, y_val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T00:06:31.157747Z",
     "iopub.status.busy": "2022-03-31T00:06:31.157064Z",
     "iopub.status.idle": "2022-03-31T00:06:31.165205Z",
     "shell.execute_reply": "2022-03-31T00:06:31.164131Z",
     "shell.execute_reply.started": "2022-03-31T00:06:31.157705Z"
    },
    "id": "wGx0F0g145Ki"
   },
   "outputs": [],
   "source": [
    "info.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "431dc63d",
    "outputId": "386df377-59c9-431c-848d-14672cbae5da"
   },
   "outputs": [],
   "source": [
    "## create fake results\n",
    "import numpy as np\n",
    "\n",
    "# All answers\n",
    "gtlist = [x['answers'] for x in data]\n",
    "\n",
    "# Save the accuracies\n",
    "acc_list = []\n",
    "i = 0\n",
    "\n",
    "# Compute accuracy for each image\n",
    "for pred in results:\n",
    "\n",
    "    # Get the GT answer list and preprocess\n",
    "    gt_ans = gtlist[i] \n",
    "    gt_ans = [x['answer'] for x in gt_ans]\n",
    "    gt_ans = [x.lower() for x in gt_ans]\n",
    "\n",
    "    # Compute accuracy (compare with at least 3 human answers)\n",
    "    cur_acc = np.minimum(1.0, gt_ans.count(pred)/3.0)\n",
    "\n",
    "    acc_list.append(cur_acc)\n",
    "    i +=1\n",
    "\n",
    "print ('Accuracy: {}'.format(round(np.mean(acc_list), 2)))\n",
    "\n",
    "## save results to results.csv\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"results.csv\", header = None, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjHxZrJtrHlQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
